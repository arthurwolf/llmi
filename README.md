# llmi

Large-Language-Model to Machine Interface Open-Source project.

## Goal

Large Language Models (LLMs) are very good at some things (writing, summarizing, answering factual questions), but also remarkably bad at others (real-time information, complex logic, information formatting, tool usage, verification, structured/long output).

Some of those things they are bad at, they could get better at if they were able to get help from tools/machines that currently 

This project aims to create:

* Specifications
* Training datasets
* Large language models
* And tools

in order to create LLMs with the ability to use computers to improve their abilities.

## Implementation

The plan here is, for each/all of the features, to:

1. Write down a specification of what the feature should be able to accomplish
2. Plan and document how to accomplish/implement it.
3. Create a training dataset for this feature.
4. Once all datasets exist, train a LLM using these datasets.
5. Test and improve the LLM.
6. Write tools that are able to take advantage of the new features.

## Features

This is a presentation of each feature this project aims to implement.

PRs for extra features (and any contribution) are extremely welcome:

### Recursive redaction.

Goal: Allow LLMs to write large bodies of text recursively, enabling chapters, sub-chapters etc to be writtens separately (either in series or in parralel) and then joined together.

This would allow writing much longer content than is currently allowed by LLMs, which are limited by their context window, the only disadvantage being this would only be possible for "structured" content.

The way this would be implemented is, the LLM would first generate a table of contents for the body of text, and then in each chapter, insert a tag asking the system to write that chapter.

For example, if asked:

```
write a dissertation explaining why the earth is not flat
```

The LLM would generate something in this format:

```
    # 1. Introduction

      <chapter context=true title="Introduction">
        The debate surrounding the shape of the Earth seems like an archaic one, but it has resurfaced in modern times due to social media and the availability of misleading information online.
        It's crucial to address these misconceptions by leveraging empirical evidence and scientific reasoning.
      </chapter>

    # 2. History of Flat Earth Theory

      <chapter context=true title="History of Flat Earth Theory">
        The flat Earth theory has its roots in ancient civilizations but was largely debunked by the advent of the Scientific Revolution.
        Philosophers and scientists like Pythagoras, Aristotle, and Copernicus presented evidence supporting the Earth's spherical shape, which has stood the test of time.
      </chapter>

    # 3. Fundamental Laws of Physics

      <chapter context=true title="Fundamental Laws of Physics">

    [etc...]
```

Then, as the output is being generated by running the LLM, each time a `<chapter>` tag is generated, when the `</chapter>` tag is found, the system will:

1. Create a new prompt from that tag
2. Use it to generate the new chapter
3. Replace, in the output, the `<chapter>` tag with the generated output.






